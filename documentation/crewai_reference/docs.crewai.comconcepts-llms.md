# Source: https://docs.crewai.com/concepts/llms

## URL: https://docs.crewai.com/concepts/llms

Title: LLMs - CrewAI

URL Source: https://docs.crewai.com/concepts/llms

Markdown Content:
LLMs - CrewAI
===============
  

[CrewAI home page![Image 5: light logo](https://mintlify.s3.us-west-1.amazonaws.com/crewai/crew_only_logo.png)![Image 6: dark logo](https://mintlify.s3.us-west-1.amazonaws.com/crewai/crew_only_logo.png)](https://docs.crewai.com/)

Search CrewAI docs

*   [crewAIInc/crewAI](https://github.com/crewAIInc/crewAI)
*   [crewAIInc/crewAI](https://github.com/crewAIInc/crewAI)

Search...

Navigation

Core Concepts

LLMs

[Get Started](https://docs.crewai.com/introduction)[Examples](https://docs.crewai.com/examples/example)

[CrewAI home page![Image 7: light logo](https://mintlify.s3.us-west-1.amazonaws.com/crewai/crew_only_logo.png)![Image 8: dark logo](https://mintlify.s3.us-west-1.amazonaws.com/crewai/crew_only_logo.png)](https://docs.crewai.com/)

*   [Community](https://community.crewai.com/)
*   [Changelog](https://github.com/crewAIInc/crewAI/releases)

##### Get Started

*   [Introduction](https://docs.crewai.com/introduction)
*   [Installation](https://docs.crewai.com/installation)
*   [Quickstart](https://docs.crewai.com/quickstart)

##### Core Concepts

*   [Agents](https://docs.crewai.com/concepts/agents)
*   [Tasks](https://docs.crewai.com/concepts/tasks)
*   [Crews](https://docs.crewai.com/concepts/crews)
*   [Flows](https://docs.crewai.com/concepts/flows)
*   [Knowledge](https://docs.crewai.com/concepts/knowledge)
*   [LLMs](https://docs.crewai.com/concepts/llms)
*   [Processes](https://docs.crewai.com/concepts/processes)
*   [Collaboration](https://docs.crewai.com/concepts/collaboration)
*   [Training](https://docs.crewai.com/concepts/training)
*   [Memory](https://docs.crewai.com/concepts/memory)
*   [Planning](https://docs.crewai.com/concepts/planning)
*   [Testing](https://docs.crewai.com/concepts/testing)
*   [CLI](https://docs.crewai.com/concepts/cli)
*   [Tools](https://docs.crewai.com/concepts/tools)
*   [Using LangChain Tools](https://docs.crewai.com/concepts/langchain-tools)
*   [Using LlamaIndex Tools](https://docs.crewai.com/concepts/llamaindex-tools)

##### How to Guides

*   [Create Custom Tools](https://docs.crewai.com/how-to/create-custom-tools)
*   [Sequential Processes](https://docs.crewai.com/how-to/sequential-process)
*   [Hierarchical Process](https://docs.crewai.com/how-to/hierarchical-process)
*   [Create Your Own Manager Agent](https://docs.crewai.com/how-to/custom-manager-agent)
*   [Connect to any LLM](https://docs.crewai.com/how-to/llm-connections)
*   [Customize Agents](https://docs.crewai.com/how-to/customizing-agents)
*   [Coding Agents](https://docs.crewai.com/how-to/coding-agents)
*   [Force Tool Output as Result](https://docs.crewai.com/how-to/force-tool-output-as-result)
*   [Human Input on Execution](https://docs.crewai.com/how-to/human-input-on-execution)
*   [Kickoff Crew Asynchronously](https://docs.crewai.com/how-to/kickoff-async)
*   [Kickoff Crew for Each](https://docs.crewai.com/how-to/kickoff-for-each)
*   [Replay Tasks from Latest Crew Kickoff](https://docs.crewai.com/how-to/replay-tasks-from-latest-crew-kickoff)
*   [Conditional Tasks](https://docs.crewai.com/how-to/conditional-tasks)
*   [Agent Monitoring with AgentOps](https://docs.crewai.com/how-to/agentops-observability)
*   [Agent Monitoring with Langtrace](https://docs.crewai.com/how-to/langtrace-observability)
*   [Agent Monitoring with OpenLIT](https://docs.crewai.com/how-to/openlit-observability)

##### Tools

*   [Browserbase Web Loader](https://docs.crewai.com/tools/browserbaseloadtool)
*   [Code Docs RAG Search](https://docs.crewai.com/tools/codedocssearchtool)
*   [Code Interpreter](https://docs.crewai.com/tools/codeinterpretertool)
*   [Composio Tool](https://docs.crewai.com/tools/composiotool)
*   [CSV RAG Search](https://docs.crewai.com/tools/csvsearchtool)
*   [DALL-E Tool](https://docs.crewai.com/tools/dalletool)
*   [Directory RAG Search](https://docs.crewai.com/tools/directorysearchtool)
*   [Directory Read](https://docs.crewai.com/tools/directoryreadtool)
*   [DOCX RAG Search](https://docs.crewai.com/tools/docxsearchtool)
*   [EXA Search Web Loader](https://docs.crewai.com/tools/exasearchtool)
*   [File Read](https://docs.crewai.com/tools/filereadtool)
*   [File Write](https://docs.crewai.com/tools/filewritetool)
*   [Firecrawl Crawl Website](https://docs.crewai.com/tools/firecrawlcrawlwebsitetool)
*   [Firecrawl Scrape Website](https://docs.crewai.com/tools/firecrawlscrapewebsitetool)
*   [Firecrawl Search](https://docs.crewai.com/tools/firecrawlsearchtool)
*   [Github Search](https://docs.crewai.com/tools/githubsearchtool)
*   [Google Serper Search](https://docs.crewai.com/tools/serperdevtool)
*   [JSON RAG Search](https://docs.crewai.com/tools/jsonsearchtool)
*   [MDX RAG Search](https://docs.crewai.com/tools/mdxsearchtool)
*   [MySQL RAG Search](https://docs.crewai.com/tools/mysqltool)
*   [NL2SQL Tool](https://docs.crewai.com/tools/nl2sqltool)
*   [PDF RAG Search](https://docs.crewai.com/tools/pdfsearchtool)
*   [PG RAG Search](https://docs.crewai.com/tools/pgsearchtool)
*   [Scrape Website](https://docs.crewai.com/tools/scrapewebsitetool)
*   [Selenium Scraper](https://docs.crewai.com/tools/seleniumscrapingtool)
*   [Spider Scraper](https://docs.crewai.com/tools/spidertool)
*   [TXT RAG Search](https://docs.crewai.com/tools/txtsearchtool)
*   [Vision Tool](https://docs.crewai.com/tools/visiontool)
*   [Website RAG Search](https://docs.crewai.com/tools/websitesearchtool)
*   [XML RAG Search](https://docs.crewai.com/tools/xmlsearchtool)
*   [YouTube Channel RAG Search](https://docs.crewai.com/tools/youtubechannelsearchtool)
*   [YouTube Video RAG Search](https://docs.crewai.com/tools/youtubevideosearchtool)

##### Telemetry

*   [Telemetry](https://docs.crewai.com/telemetry)

Core Concepts

LLMs
====

A comprehensive guide to configuring and using Large Language Models (LLMs) in your CrewAI projects

CrewAI integrates with multiple LLM providers through LiteLLM, giving you the flexibility to choose the right model for your specific use case. This guide will help you understand how to configure and use different LLM providers in your CrewAI projects.

[​](https://docs.crewai.com/concepts/llms#what-are-llms)

What are LLMs?
--------------------------------------------------------------------------

Large Language Models (LLMs) are the core intelligence behind CrewAI agents. They enable agents to understand context, make decisions, and generate human-like responses. Here’s what you need to know:

LLM Basics
----------

Large Language Models are AI systems trained on vast amounts of text data. They power the intelligence of your CrewAI agents, enabling them to understand and generate human-like text.

Context Window
--------------

The context window determines how much text an LLM can process at once. Larger windows (e.g., 128K tokens) allow for more context but may be more expensive and slower.

Temperature
-----------

Temperature (0.0 to 1.0) controls response randomness. Lower values (e.g., 0.2) produce more focused, deterministic outputs, while higher values (e.g., 0.8) increase creativity and variability.

Provider Selection
------------------

Each LLM provider (e.g., OpenAI, Anthropic, Google) offers different models with varying capabilities, pricing, and features. Choose based on your needs for accuracy, speed, and cost.

[​](https://docs.crewai.com/concepts/llms#available-models-and-their-capabilities)

Available Models and Their Capabilities
-----------------------------------------------------------------------------------------------------------------------------

Here’s a detailed breakdown of supported models and their capabilities, you can compare performance at [lmarena.ai](https://lmarena.ai/?leaderboard) and [artificialanalysis.ai](https://artificialanalysis.ai/):

*   OpenAI
*   Nvidia NIM
*   Gemini
*   Groq
*   Others

| Model | Context Window | Best For |
| --- | --- | --- |
| GPT-4 | 8,192 tokens | High-accuracy tasks, complex reasoning |
| GPT-4 Turbo | 128,000 tokens | Long-form content, document analysis |
| GPT-4o & GPT-4o-mini | 128,000 tokens | Cost-effective large context processing |

1 token ≈ 4 characters in English. For example, 8,192 tokens ≈ 32,768 characters or about 6,000 words.

[​](https://docs.crewai.com/concepts/llms#setting-up-your-llm)

Setting Up Your LLM
-------------------------------------------------------------------------------------

There are three ways to configure LLMs in CrewAI. Choose the method that best fits your workflow:

*   1\. Environment Variables
*   2\. YAML Configuration
*   3\. Direct Code

The simplest way to get started. Set these variables in your environment:

```bash
# Required: Your API key for authentication
OPENAI_API_KEY=<your-api-key>

# Optional: Default model selection
OPENAI_MODEL_NAME=gpt-4o-mini  # Default if not set

# Optional: Organization ID (if applicable)
OPENAI_ORGANIZATION_ID=<your-org-id>
```

Never commit API keys to version control. Use environment files (.env) or your system’s secret management.

[​](https://docs.crewai.com/concepts/llms#advanced-features-and-optimization)

Advanced Features and Optimization
-------------------------------------------------------------------------------------------------------------------

Learn how to get the most out of your LLM configuration:

Context Window Management

CrewAI includes smart context management features:

```python
from crewai import LLM

# CrewAI automatically handles:
# 1. Token counting and tracking
# 2. Content summarization when needed
# 3. Task splitting for large contexts

llm = LLM(
    model="gpt-4",
    max_tokens=4000,  # Limit response length
)
```

Best practices for context management:

1.  Choose models with appropriate context windows
2.  Pre-process long inputs when possible
3.  Use chunking for large documents
4.  Monitor token usage to optimize costs

Performance Optimization

1

Token Usage Optimization

Choose the right context window for your task:

*   Small tasks (up to 4K tokens): Standard models
*   Medium tasks (between 4K-32K): Enhanced models
*   Large tasks (over 32K): Large context models

```python
# Configure model with appropriate settings
llm = LLM(
    model="openai/gpt-4-turbo-preview",
    temperature=0.7,    # Adjust based on task
    max_tokens=4096,    # Set based on output needs
    timeout=300        # Longer timeout for complex tasks
)
```

*   Lower temperature (0.1 to 0.3) for factual responses
*   Higher temperature (0.7 to 0.9) for creative tasks

2

Best Practices

1.  Monitor token usage
2.  Implement rate limiting
3.  Use caching when possible
4.  Set appropriate max\_tokens limits

Remember to regularly monitor your token usage and adjust your configuration as needed to optimize costs and performance.

[​](https://docs.crewai.com/concepts/llms#provider-configuration-examples)

Provider Configuration Examples
-------------------------------------------------------------------------------------------------------------

OpenAI

Code

```python
# Required
OPENAI_API_KEY=sk-...

# Optional
OPENAI_API_BASE=<custom-base-url>
OPENAI_ORGANIZATION=<your-org-id>
```

Example usage:

Code

```python
from crewai import LLM

llm = LLM(
    model="gpt-4",
    temperature=0.8,
    max_tokens=150,
    top_p=0.9,
    frequency_penalty=0.1,
    presence_penalty=0.1,
    stop=["END"],
    seed=42
)
```

Anthropic

Code

```python
ANTHROPIC_API_KEY=sk-ant-...
```

Example usage:

Code

```python
llm = LLM(
    model="anthropic/claude-3-sonnet-20240229-v1:0",
    temperature=0.7
)
```

Google

Code

```python
# Option 1. Gemini accessed with an API key.
# https://ai.google.dev/gemini-api/docs/api-key
GEMINI_API_KEY=<your-api-key>

# Option 2. Vertex AI IAM credentials for Gemini, Anthropic, and anything in the Model Garden.
# https://cloud.google.com/vertex-ai/generative-ai/docs/overview
```

Example usage:

Code

```python
llm = LLM(
    model="gemini/gemini-1.5-pro-latest",
    temperature=0.7
)
```

Azure

Code

```python
# Required
AZURE_API_KEY=<your-api-key>
AZURE_API_BASE=<your-resource-url>
AZURE_API_VERSION=<api-version>

# Optional
AZURE_AD_TOKEN=<your-azure-ad-token>
AZURE_API_TYPE=<your-azure-api-type>
```

Example usage:

Code

```python
llm = LLM(
    model="azure/gpt-4",
    api_version="2023-05-15"
)
```

AWS Bedrock

Code

```python
AWS_ACCESS_KEY_ID=<your-access-key>
AWS_SECRET_ACCESS_KEY=<your-secret-key>
AWS_DEFAULT_REGION=<your-region>
```

Example usage:

Code

```python
llm = LLM(
    model="bedrock/anthropic.claude-3-sonnet-20240229-v1:0"
)
```

Mistral

Code

```python
MISTRAL_API_KEY=<your-api-key>
```

Example usage:

Code

```python
llm = LLM(
    model="mistral/mistral-large-latest",
    temperature=0.7
)
```

Nvidia NIM

Code

```python
NVIDIA_API_KEY=<your-api-key>
```

Example usage:

Code

```python
llm = LLM(
    model="nvidia_nim/meta/llama3-70b-instruct",
    temperature=0.7
)
```

Groq

Code

```python
GROQ_API_KEY=<your-api-key>
```

Example usage:

Code

```python
llm = LLM(
    model="groq/llama-3.2-90b-text-preview",
    temperature=0.7
)
```

IBM watsonx.ai

Code

```python
# Required
WATSONX_URL=<your-url>
WATSONX_APIKEY=<your-apikey>
WATSONX_PROJECT_ID=<your-project-id>

# Optional
WATSONX_TOKEN=<your-token>
WATSONX_DEPLOYMENT_SPACE_ID=<your-space-id>
```

Example usage:

Code

```python
llm = LLM(
    model="watsonx/meta-llama/llama-3-1-70b-instruct",
    base_url="https://api.watsonx.ai/v1"
)
```

Ollama (Local LLMs)

1.  Install Ollama: [ollama.ai](https://ollama.ai/)
2.  Run a model: `ollama run llama2`
3.  Configure:

Code

```python
llm = LLM(
    model="ollama/llama3:70b",
    base_url="http://localhost:11434"
)
```

Fireworks AI

Code

```python
FIREWORKS_API_KEY=<your-api-key>
```

Example usage:

Code

```python
llm = LLM(
    model="fireworks_ai/accounts/fireworks/models/llama-v3-70b-instruct",
    temperature=0.7
)
```

Perplexity AI

Code

```python
PERPLEXITY_API_KEY=<your-api-key>
```

Example usage:

Code

```python
llm = LLM(
    model="llama-3.1-sonar-large-128k-online",
    base_url="https://api.perplexity.ai/"
)
```

Hugging Face

Code

```python
HUGGINGFACE_API_KEY=<your-api-key>
```

Example usage:

Code

```python
llm = LLM(
    model="huggingface/meta-llama/Meta-Llama-3.1-8B-Instruct",
    base_url="your_api_endpoint"
)
```

SambaNova

Code

```python
SAMBANOVA_API_KEY=<your-api-key>
```

Example usage:

Code

```python
llm = LLM(
    model="sambanova/Meta-Llama-3.1-8B-Instruct",
    temperature=0.7
)
```

Cerebras

Code

```python
# Required
CEREBRAS_API_KEY=<your-api-key>
```

Example usage:

Code

```python
llm = LLM(
    model="cerebras/llama3.1-70b",
    temperature=0.7,
    max_tokens=8192
)
```

Cerebras features:

*   Fast inference speeds
*   Competitive pricing
*   Good balance of speed and quality
*   Support for long context windows

[​](https://docs.crewai.com/concepts/llms#common-issues-and-solutions)

Common Issues and Solutions
-----------------------------------------------------------------------------------------------------

*   Authentication
*   Model Names
*   Context Length

Most authentication issues can be resolved by checking API key format and environment variable names.

```bash
# OpenAI
OPENAI_API_KEY=sk-...

# Anthropic
ANTHROPIC_API_KEY=sk-ant-...
```

[​](https://docs.crewai.com/concepts/llms#getting-help)

Getting Help
-----------------------------------------------------------------------

If you need assistance, these resources are available:

[LiteLLM Documentation --------------------- Comprehensive documentation for LiteLLM integration and troubleshooting common issues.](https://docs.litellm.ai/docs/)[GitHub Issues ------------- Report bugs, request features, or browse existing issues for solutions.](https://github.com/joaomdmoura/crewAI/issues)[Community Forum --------------- Connect with other CrewAI users, share experiences, and get help from the community.](https://community.crewai.com/)

Best Practices for API Key Security:

*   Use environment variables or secure vaults
*   Never commit keys to version control
*   Rotate keys regularly
*   Use separate keys for development and production
*   Monitor key usage for unusual patterns

Was this page helpful?

YesNo

[Knowledge](https://docs.crewai.com/concepts/knowledge)[Processes](https://docs.crewai.com/concepts/processes)

[website](https://crewai.com/)[x](https://x.com/crewAIInc)[github](https://github.com/crewAIInc/crewAI)[linkedin](https://www.linkedin.com/company/crewai-inc)[youtube](https://youtube.com/@crewAIInc)

[Powered by Mintlify](https://mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.crewai.com)

On this page

*   [What are LLMs?](https://docs.crewai.com/concepts/llms#what-are-llms)
*   [Available Models and Their Capabilities](https://docs.crewai.com/concepts/llms#available-models-and-their-capabilities)
*   [Setting Up Your LLM](https://docs.crewai.com/concepts/llms#setting-up-your-llm)
*   [Advanced Features and Optimization](https://docs.crewai.com/concepts/llms#advanced-features-and-optimization)
*   [Provider Configuration Examples](https://docs.crewai.com/concepts/llms#provider-configuration-examples)
*   [Common Issues and Solutions](https://docs.crewai.com/concepts/llms#common-issues-and-solutions)
*   [Getting Help](https://docs.crewai.com/concepts/llms#getting-help)

---


# Crawl Statistics

- **Source:** https://docs.crewai.com/concepts/llms
- **Depth:** 1
- **Pages processed:** 1
- **Crawl method:** api
- **Duration:** 2.51 seconds
- **Crawl completed:** 12/29/2024, 4:12:18 PM

